{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import BigWindowHAI\n",
    "data = pd.read_csv(\"normalized_HAI.csv\")\n",
    "splits = BigWindowHAI.get_data(data = data, n_splits=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for split 1 : \n",
      "is most similar with 0 is 64.96496229525859\n",
      "for split 2 : \n",
      "is most similar with 1 is 62.182200417203795\n",
      "for split 3 : \n",
      "is most similar with 1 is 46.915163806580374\n",
      "for split 4 : \n",
      "is most similar with 2 is 322.7665954404913\n",
      "for split 5 : \n",
      "is most similar with 1 is 84.09045956592809\n",
      "for split 6 : \n",
      "is most similar with 2 is 46.80315582741101\n",
      "for split 7 : \n",
      "is most similar with 3 is 37.62224381684561\n",
      "for split 8 : \n",
      "is most similar with 7 is 28.776663150742944\n",
      "for split 9 : \n",
      "is most similar with 1 is 24.064076578967846\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#now let us check the similarity between these datasets. \n",
    "def get_metrics(index_of_split):   \n",
    "    stats_df3 = pd.DataFrame({\n",
    "        'mean': splits[index_of_split].mean(),      # Mean of each column\n",
    "        'std': splits[index_of_split].std(),        # Std of each column\n",
    "        'median': splits[index_of_split].median(),  # Median of each column\n",
    "        'min': splits[index_of_split].min(),        # Minimum value\n",
    "        'max': splits[index_of_split].max(),        # Maximum value\n",
    "        'range': splits[index_of_split].max() - splits[index_of_split].min(),  # Range\n",
    "        'iqr': splits[index_of_split].quantile(0.75) - splits[index_of_split].quantile(0.25),  # Interquartile Range\n",
    "        'skewness': splits[index_of_split].skew(),  # Skewness of each column\n",
    "        'kurtosis': splits[index_of_split].kurt(),  # Kurtosis of each column\n",
    "    })\n",
    "    return stats_df3\n",
    "\n",
    "def compare_metrics(stats1, stats2, method='euclidean'):\n",
    "    # Ensure stats1 and stats2 are aligned\n",
    "    stats1, stats2 = stats1.align(stats2, join='inner', axis=0)\n",
    "    \n",
    "    # Calculate the differences\n",
    "    diff = stats1.values - stats2.values\n",
    "    \n",
    "    if method == 'euclidean':\n",
    "        # Euclidean distance\n",
    "        score = np.sqrt(np.sum(diff ** 2))\n",
    "    elif method == 'manhattan':\n",
    "        # Manhattan distance (sum of absolute differences)\n",
    "        score = np.sum(np.abs(diff))\n",
    "    elif method == 'cosine':\n",
    "        # Cosine similarity (1 - cosine distance)\n",
    "        dot_product = np.sum(stats1.values * stats2.values)\n",
    "        norm1 = np.sqrt(np.sum(stats1.values ** 2))\n",
    "        norm2 = np.sqrt(np.sum(stats2.values ** 2))\n",
    "        score = 1 - dot_product / (norm1 * norm2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose 'euclidean', 'manhattan', or 'cosine'.\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def check_similarity(split1index, split2index, method= 'euclidean'):\n",
    "    return compare_metrics(get_metrics(split1index) , get_metrics(split2index), method=method)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#here we check how similar our data splits to each other\n",
    "positive_infinity = float('inf')\n",
    "\n",
    "for i in range (1,10):\n",
    "    min= float('inf')\n",
    "    for j in range(0, i):\n",
    "        if (check_similarity(i, j) < min):\n",
    "            min = check_similarity(i,j)\n",
    "            most_similar = j\n",
    "    print(f'for split {i} : ')\n",
    "    print(f'is most similar with {most_similar} is {min}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Auto-Determined Similarity Threshold: 39.22531\n",
      "Split 1 is most similar to Split 0 with score: 64.96496\n",
      "‚úÖ Keeping Split 1\n",
      "Split 2 is most similar to Split 1 with score: 62.18220\n",
      "‚úÖ Keeping Split 2\n",
      "Split 3 is most similar to Split 1 with score: 46.91516\n",
      "‚úÖ Keeping Split 3\n",
      "Split 4 is most similar to Split 2 with score: 322.76660\n",
      "‚úÖ Keeping Split 4\n",
      "Split 5 is most similar to Split 1 with score: 84.09046\n",
      "‚úÖ Keeping Split 5\n",
      "Split 6 is most similar to Split 2 with score: 46.80316\n",
      "‚úÖ Keeping Split 6\n",
      "Split 7 is most similar to Split 3 with score: 37.62224\n",
      "‚ùå Skipping Split 7 (Too Similar)\n",
      "Split 8 is most similar to Split 6 with score: 32.28200\n",
      "‚ùå Skipping Split 8 (Too Similar)\n",
      "Split 9 is most similar to Split 1 with score: 24.06408\n",
      "‚ùå Skipping Split 9 (Too Similar)\n",
      "\n",
      "Final Selected Splits: [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_metrics(index_of_split):   \n",
    "    return pd.DataFrame({\n",
    "        'mean': splits[index_of_split].mean(),\n",
    "        'std': splits[index_of_split].std(),\n",
    "        'median': splits[index_of_split].median(),\n",
    "        'min': splits[index_of_split].min(),\n",
    "        'max': splits[index_of_split].max(),\n",
    "        'range': splits[index_of_split].max() - splits[index_of_split].min(),\n",
    "        'iqr': splits[index_of_split].quantile(0.75) - splits[index_of_split].quantile(0.25),\n",
    "        'skewness': splits[index_of_split].skew(),\n",
    "        'kurtosis': splits[index_of_split].kurt(),\n",
    "    })\n",
    "\n",
    "def compare_metrics(stats1, stats2):\n",
    "    stats1, stats2 = stats1.align(stats2, join='inner', axis=0)\n",
    "    diff = stats1.values - stats2.values\n",
    "    return np.sqrt(np.sum(diff ** 2))  # Euclidean distance\n",
    "\n",
    "# Compute similarity scores between all split pairs\n",
    "similarity_scores = []\n",
    "for i in range(1, 10):\n",
    "    for j in range(i):\n",
    "        score = compare_metrics(get_metrics(i), get_metrics(j))\n",
    "        similarity_scores.append(score)\n",
    "\n",
    "# **Determine the threshold dynamically**\n",
    "SIMILARITY_THRESHOLD = np.percentile(similarity_scores, 10)  # Skip top 10% most similar splits\n",
    "print(f\"üîπ Auto-Determined Similarity Threshold: {SIMILARITY_THRESHOLD:.5f}\")\n",
    "\n",
    "# **Now, filter splits based on this threshold**\n",
    "selected_splits = [0]  # Always keep first split\n",
    "\n",
    "for i in range(1, 10):\n",
    "    min_similarity = float('inf')\n",
    "    most_similar = None\n",
    "\n",
    "    for j in selected_splits:\n",
    "        similarity_score = compare_metrics(get_metrics(i), get_metrics(j))\n",
    "\n",
    "        if similarity_score < min_similarity:\n",
    "            min_similarity = similarity_score\n",
    "            most_similar = j\n",
    "\n",
    "    print(f\"Split {i} is most similar to Split {most_similar} with score: {min_similarity:.5f}\")\n",
    "\n",
    "    # **Decide: Skip or Keep**\n",
    "    if min_similarity >= SIMILARITY_THRESHOLD:\n",
    "        selected_splits.append(i)  # Keep the split\n",
    "        print(f\"‚úÖ Keeping Split {i}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Skipping Split {i} (Too Similar)\")\n",
    "\n",
    "print(\"\\nFinal Selected Splits:\", selected_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
